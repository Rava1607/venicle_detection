{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CarsDetect.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAyJtt8TJZRw"
      },
      "source": [
        "## Скачаем наш датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hS_LPVXGhkb",
        "outputId": "21db9c7b-bca2-439d-ef3a-8cbce7796a94"
      },
      "source": [
        "!wget -c http://ai.stanford.edu/~jkrause/car196/car_ims.tgz -O - | tar -xz\n",
        "!wget -c http://ai.stanford.edu/~jkrause/car196/cars_annos.mat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-                   100%[===================>]   1.82G  20.5MB/s    in 1m 42s  \n",
            "\n",
            "2021-06-12 10:51:35 (18.2 MB/s) - written to stdout [1956628579/1956628579]\n",
            "\n",
            "--2021-06-12 10:51:35--  http://ai.stanford.edu/~jkrause/car196/cars_annos.mat\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 394471 (385K) [text/plain]\n",
            "Saving to: ‘cars_annos.mat’\n",
            "\n",
            "cars_annos.mat      100%[===================>] 385.23K   408KB/s    in 0.9s    \n",
            "\n",
            "2021-06-12 10:51:37 (408 KB/s) - ‘cars_annos.mat’ saved [394471/394471]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbpvUMl0JcaX"
      },
      "source": [
        "## Сконвертируем датасет в формат YOLO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DQPc7Tqz6-R"
      },
      "source": [
        "import scipy.io as io\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "fname ='/content/cars_annos.mat'\n",
        "data  = io.loadmat(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "712YYxLn0AIl",
        "outputId": "7b690ce9-2d0e-4f98-afa4-3cf831116684"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "path_train = '/content/train/'\n",
        "path_test = '/content/test/'\n",
        "path_val = '/content/val/'\n",
        "\n",
        "labels_path_train = path_train + 'labels/'\n",
        "labels_path_test = path_test + 'labels/'\n",
        "labels_path_val = path_val + 'labels/'\n",
        "img_path_train = path_train + 'images/'\n",
        "img_path_test = path_test + 'images/'\n",
        "img_path_val = path_val + 'images/'\n",
        "\n",
        "for path in [labels_path_train, labels_path_test, \n",
        "             img_path_train, img_path_test,\n",
        "             labels_path_val, img_path_val]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def parse_data(data):\n",
        "    '''Распарсим данные и разложим их в 3 кучки. Train, test и val'''\n",
        "    for num, i in tqdm(enumerate(range(len(data['annotations'][0])))):\n",
        "        sample = data['annotations'][0][i]\n",
        "\n",
        "        img_path = sample[0][0]\n",
        "        bbox_x1 = sample[1][0][0]\n",
        "        bbox_y1 = sample[2][0][0]\n",
        "        bbox_x2 = sample[3][0][0]\n",
        "        bbox_y2 = sample[4][0][0]\n",
        "        class_label = sample[5][0][0]-1\n",
        "        test = sample[6][0][0]\n",
        "\n",
        "        image = Image.open(img_path)\n",
        "        width, height = image.size\n",
        "\n",
        "        label_name = img_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "        x1 = bbox_x1/width\n",
        "        x2 = bbox_x2/width\n",
        "        y1 = bbox_y1/height\n",
        "        y2 = bbox_y2/height\n",
        "\n",
        "        bbox_width = x2 - x1\n",
        "        bbox_height = y2 - y1\n",
        "\n",
        "        labels_path = labels_path_train\n",
        "        img_path_final = img_path_train\n",
        "        if num in np.random.randint(size=(200), low=0, high=len(data['annotations'][0])):\n",
        "            labels_path = labels_path_val\n",
        "            img_path_final = img_path_val\n",
        "        if num in np.random.randint(size=(1000), low=0, high=len(data['annotations'][0])):\n",
        "            labels_path = labels_path_test\n",
        "            img_path_final = img_path_test\n",
        "        with open(labels_path + label_name + '.txt', mode=\"w\") as label_file:\n",
        "            label_file.write(\n",
        "                f\"{class_label} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
        "            )\n",
        "            os.rename(img_path, img_path_final + label_name + '.jpg')\n",
        "        \n",
        "parse_data(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162it [00:00, 1613.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16185it [00:07, 2081.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-DLEUtp0CgY"
      },
      "source": [
        "# def class2label(data, indx):\n",
        "#     return data['class_names'][0][indx-1][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1hdAYipJvgw"
      },
      "source": [
        "## Создадим файл с настройками для нашей YOLO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "oXE5r-irZvSv",
        "outputId": "84c89801-7c89-4e23-cd69-b652f041ce77"
      },
      "source": [
        "import yaml\n",
        "%cd /content/\n",
        "names = np.array([x[0] for x in data['class_names'][0]]).tolist()\n",
        "\n",
        "setting = dict(\n",
        "    train = path_train,\n",
        "    val = path_val,\n",
        "    test = path_test,\n",
        "    nc = 196,\n",
        "    names = names\n",
        ")\n",
        "\n",
        "with open('/content/settings.yaml', 'w') as outfile:\n",
        "    yaml.dump(setting, outfile, default_flow_style=False, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-891805c2bbdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m setting = dict(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTutloe_JzsF"
      },
      "source": [
        "## Скачаем YOLOv5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "paZGgop4BjiC",
        "outputId": "0529e647-b0a7-4ce5-8815-640e0821a977"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 7103, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 7103 (delta 123), reused 150 (delta 80), pack-reused 6894\u001b[K\n",
            "Receiving objects: 100% (7103/7103), 9.16 MiB | 20.04 MiB/s, done.\n",
            "Resolving deltas: 100% (4861/4861), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.9.1+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.34.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Installing collected packages: PyYAML, thop\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 thop-0.0.31.post2005241907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l05S9M9tGU_"
      },
      "source": [
        "# !pip install wandb # Для мониторинга обучения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-p98PcZJ2_u"
      },
      "source": [
        "## Затюним нашу предобученную YOLOv5. Будем делать resize изображений, что бы быстрее училась и все влезло в память"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-TBqhuwY8oG",
        "outputId": "c3d550a7-897d-410e-dd54-373d231c3bfa"
      },
      "source": [
        "%cd /content/yolov5/\n",
        "!python train.py --batch 48 --weights yolov5l.pt --data /content/settings.yaml --epochs 50 --cache --img 256 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-180-ge8c5237 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=48, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/settings.yaml', device='', entity=None, epochs=50, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[256, 256], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=48, upload_dataset=False, weights='yolov5l.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2021-06-11 17:07:52.930688: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrimeacs1\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-06-11 17:07:55.080275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crimeacs1/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/crimeacs1/YOLOv5/runs/31iv1ffr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20210611_170754-31iv1ffr\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5l.pt to yolov5l.pt...\n",
            "100% 90.2M/90.2M [00:01<00:00, 75.0MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=196\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
            "  9                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1   1082385  models.yolo.Detect                      [196, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 499 layers, 47681425 parameters, 47681425 gradients\n",
            "\n",
            "Transferred 644/650 items from yolov5l.pt\n",
            "Scaled weight_decay = 0.000375\n",
            "Optimizer groups: 110 .bias, 110 conv.weight, 107 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels.cache' images and labels... 15000 found, 0 missing, 0 empty, 0 corrupted: 100% 15000/15000 [00:00<00:00, 98457840.38it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.0GB): 100% 15000/15000 [01:25<00:00, 176.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/val/labels' images and labels...200 found, 0 missing, 0 empty, 0 corrupted: 100% 200/200 [00:00<00:00, 753.69it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/val/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB): 100% 200/200 [00:02<00:00, 97.43it/s] \n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.50, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 256 train, 256 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     11.1G   0.04128    0.0161    0.1211    0.1785        57       256: 100% 313/313 [02:08<00:00,  2.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.28s/it]\n",
            "                 all        200        200    0.00776          1      0.023     0.0193\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     11.1G   0.02319  0.009422    0.1193    0.1519        71       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.76it/s]\n",
            "                 all        200        200    0.00795      0.945     0.0338     0.0293\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     11.1G   0.01877  0.008267    0.1172    0.1443        70       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.72it/s]\n",
            "                 all        200        200      0.044      0.694     0.0592     0.0535\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     11.1G   0.01713   0.00807     0.114    0.1392        61       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.73it/s]\n",
            "                 all        200        200     0.0753      0.644     0.0904     0.0819\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     11.1G   0.01643  0.007871    0.1106    0.1349        70       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.07it/s]\n",
            "                 all        200        200      0.101      0.738      0.137      0.126\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     11.1G   0.01624    0.0078    0.1072    0.1313        76       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.77it/s]\n",
            "                 all        200        200       0.43       0.37      0.146      0.135\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     11.1G   0.01603  0.007627    0.1045    0.1282        70       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.80it/s]\n",
            "                 all        200        200      0.267       0.56      0.191       0.17\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     11.1G   0.01602  0.007654     0.102    0.1257        66       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.84it/s]\n",
            "                 all        200        200      0.386      0.463      0.218      0.203\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     11.1G   0.01612  0.007735   0.09955    0.1234        67       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.82it/s]\n",
            "                 all        200        200      0.569      0.356      0.259      0.238\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     11.1G   0.01627  0.007649   0.09672    0.1206        64       256: 100% 313/313 [02:02<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.12it/s]\n",
            "                 all        200        200      0.322      0.583      0.336      0.301\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     11.1G   0.01641  0.007652   0.09406    0.1181        62       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.87it/s]\n",
            "                 all        200        200      0.319      0.561      0.389      0.359\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     11.1G   0.01669    0.0077   0.09146    0.1158        70       256: 100% 313/313 [02:02<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.92it/s]\n",
            "                 all        200        200      0.256      0.679      0.445       0.41\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     11.1G   0.01672   0.00767   0.08893    0.1133        66       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.95it/s]\n",
            "                 all        200        200      0.276      0.664      0.469      0.422\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     11.1G    0.0169  0.007723   0.08654    0.1112        66       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.95it/s]\n",
            "                 all        200        200      0.449      0.562      0.514      0.474\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     11.1G   0.01706  0.007753   0.08426    0.1091        62       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.23it/s]\n",
            "                 all        200        200      0.317      0.728      0.572      0.531\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     11.1G   0.01718  0.007694   0.08222    0.1071        66       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.01it/s]\n",
            "                 all        200        200       0.35      0.753      0.594      0.551\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     11.1G   0.01754  0.007818   0.07934    0.1047        71       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.03it/s]\n",
            "                 all        200        200      0.403      0.764      0.649      0.601\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     11.1G   0.01755   0.00769   0.07721    0.1024        57       256: 100% 313/313 [02:02<00:00,  2.56it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.09it/s]\n",
            "                 all        200        200      0.358       0.85      0.707      0.658\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     11.1G   0.01765  0.007667   0.07539    0.1007        63       256: 100% 313/313 [02:02<00:00,  2.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.09it/s]\n",
            "                 all        200        200      0.373      0.828      0.698       0.64\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     11.1G   0.01798  0.007744    0.0728   0.09852        69       256: 100% 313/313 [02:02<00:00,  2.56it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.35it/s]\n",
            "                 all        200        200      0.516      0.782      0.744      0.699\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     11.1G    0.0181  0.007745   0.07066   0.09651        58       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.11it/s]\n",
            "                 all        200        200      0.558      0.781      0.761      0.711\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     11.1G   0.01835  0.007769   0.06871   0.09483        73       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.12it/s]\n",
            "                 all        200        200      0.586      0.802      0.807       0.75\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     11.1G   0.01841  0.007737   0.06709   0.09324        62       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.06it/s]\n",
            "                 all        200        200      0.526      0.853      0.838      0.777\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     11.1G   0.01838  0.007681   0.06484    0.0909        65       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.18it/s]\n",
            "                 all        200        200      0.604      0.829      0.845      0.786\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     11.1G   0.01861  0.007689   0.06275   0.08905        63       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.39it/s]\n",
            "                 all        200        200      0.571      0.868      0.851      0.798\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     11.1G   0.01855  0.007684   0.06038   0.08662        72       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.16it/s]\n",
            "                 all        200        200      0.557      0.916      0.874      0.823\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     11.1G   0.01847  0.007641    0.0592   0.08531        63       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.14it/s]\n",
            "                 all        200        200      0.633      0.873      0.892      0.842\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     11.1G   0.01851  0.007632   0.05725   0.08339        76       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.11it/s]\n",
            "                 all        200        200      0.635      0.891      0.907      0.857\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     11.1G   0.01858  0.007625   0.05548   0.08168        70       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.13it/s]\n",
            "                 all        200        200      0.691      0.867      0.912      0.864\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     11.1G   0.01835  0.007611   0.05391   0.07987        66       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:01<00:00,  2.49it/s]\n",
            "                 all        200        200      0.686      0.882      0.938       0.89\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     11.1G   0.01838  0.007538   0.05212   0.07804        69       256: 100% 313/313 [02:01<00:00,  2.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.14it/s]\n",
            "                 all        200        200      0.722      0.876      0.941      0.892\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     11.1G   0.01848  0.007552   0.04971   0.07573        66       256: 100% 313/313 [02:01<00:00,  2.58it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:00<00:00,  3.05it/s]\n",
            "                 all        200        200      0.717      0.909      0.945      0.893\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     11.1G    0.0184  0.007544   0.05071   0.07665       145       256:   7% 21/313 [00:08<01:53,  2.57it/s]Traceback (most recent call last):\n",
            "  File \"train.py\", line 542, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 317, in train\n",
            "    scaler.step(optimizer)  # optimizer.step\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 339, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 285, in _maybe_opt_step\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 285, in <genexpr>\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 348\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/yolov5/wandb/run-20210611_170754-31iv1ffr/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/yolov5/wandb/run-20210611_170754-31iv1ffr/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/box_loss 0.01848\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/obj_loss 0.00755\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/cls_loss 0.04971\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              metrics/precision 0.71684\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 metrics/recall 0.9088\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                metrics/mAP_0.5 0.94457\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           metrics/mAP_0.5:0.95 0.89285\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/box_loss 0.00625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/obj_loss 0.00223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   val/cls_loss 0.01384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr0 0.00476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr1 0.00476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                          x/lr2 0.00476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _runtime 4141\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     _timestamp 1623435415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                          _step 31\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▁▁▂▂▅▄▅▆▄▄▃▄▅▄▄▅▄▅▆▆▇▆▇▇▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall █▇▅▄▅▁▃▂▁▃▃▅▄▃▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▁▁▂▂▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▁▁▂▂▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▄▄▃▄▂▃▃▃▂▂▃▃▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ███▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▄▇███████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▄▇███████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 197 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp3\u001b[0m: \u001b[34mhttps://wandb.ai/crimeacs1/YOLOv5/runs/31iv1ffr\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbziLuCJLJwX"
      },
      "source": [
        "## Посчитаем точность на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P5TnzSZS78P",
        "outputId": "9091bde6-6940-40d0-a346-8a0715a4ddca"
      },
      "source": [
        "import yaml\n",
        "%cd /content/\n",
        "names = np.array([x[0] for x in data['class_names'][0]]).tolist()\n",
        "\n",
        "setting = dict(\n",
        "    train = path_train,\n",
        "    val = path_test,\n",
        "    nc = 196,\n",
        "    names = names\n",
        ")\n",
        "\n",
        "with open('/content/settings_test.yaml', 'w') as outfile:\n",
        "    yaml.dump(setting, outfile, default_flow_style=False, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWCgwHCnV_YN"
      },
      "source": [
        "trained_weights = '/content/yolov5/runs/train/exp3/weights/best.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRvXQQwjLNFb",
        "outputId": "2dc0bc45-c283-4be5-d3ed-29689e65a9ab"
      },
      "source": [
        "%cd /content/yolov5/\n",
        "!python test.py --batch 48 --data /content/settings_test.yaml --weights $trained_weights --conf 0.25 --img 256"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "Namespace(augment=False, batch_size=48, conf_thres=0.25, data='/content/settings_test.yaml', device='', exist_ok=False, half=False, imgsz=256, iou_thres=0.6, name='exp', project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', verbose=False, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'])\n",
            "YOLOv5 🚀 v5.0-180-ge8c5237 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 392 layers, 47650641 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/test/labels.cache' images and labels... 985 found, 0 missing, 0 empty, 0 corrupted: 100% 985/985 [00:00<00:00, 9140242.12it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 21/21 [00:11<00:00,  1.77it/s]\n",
            "                 all        985        985      0.771      0.856      0.866      0.817\n",
            "Speed: 0.1ms pre-process, 5.2ms inference, 1.4ms NMS per image at shape (48, 3, 256, 256)\n",
            "Results saved to runs/test/exp3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ujsTEIK6X0"
      },
      "source": [
        "## Будем предсказывать наши машинки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVqOY6sbT8kM",
        "outputId": "7146c429-9088-4950-a111-84bb94573a9b"
      },
      "source": [
        "url = 'https://www.supercars.net/blog/wp-content/uploads/2016/04/2012_AstonMartin_V8VantageRoadster1.jpg'\n",
        "!wget $url "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-11 18:22:57--  https://www.supercars.net/blog/wp-content/uploads/2016/04/2012_AstonMartin_V8VantageRoadster1.jpg\n",
            "Resolving www.supercars.net (www.supercars.net)... 172.67.134.254, 104.21.6.157, 2606:4700:3030::ac43:86fe, ...\n",
            "Connecting to www.supercars.net (www.supercars.net)|172.67.134.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 254280 (248K) [image/jpeg]\n",
            "Saving to: ‘2012_AstonMartin_V8VantageRoadster1.jpg’\n",
            "\n",
            "\r          2012_Asto   0%[                    ]       0  --.-KB/s               \r2012_AstonMartin_V8 100%[===================>] 248.32K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-06-11 18:22:57 (9.05 MB/s) - ‘2012_AstonMartin_V8VantageRoadster1.jpg’ saved [254280/254280]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scn9vuWwL9_c",
        "outputId": "aee88c6f-c9fd-4de7-866f-442e0c6ffb12"
      },
      "source": [
        "!python detect.py --source /content/yolov5/2012_AstonMartin_V8VantageRoadster1.jpg --weights $trained_weights --img 256 --max-det 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, half=False, hide_conf=False, hide_labels=False, imgsz=256, iou_thres=0.45, line_thickness=3, max_det=1, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=False, source='/content/yolov5/2012_AstonMartin_V8VantageRoadster1.jpg', update=False, view_img=False, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'])\n",
            "YOLOv5 🚀 v5.0-180-ge8c5237 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 392 layers, 47650641 parameters, 0 gradients\n",
            "image 1/1 /content/yolov5/2012_AstonMartin_V8VantageRoadster1.jpg: 224x256 1 Aston Martin V8 Vantage Convertible 2012, Done. (0.021s)\n",
            "Results saved to runs/detect/exp4\n",
            "Done. (0.088s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSZcN8z5UedU",
        "outputId": "478ee0fa-3120-47f6-d36e-ef30376ee581"
      },
      "source": [
        "url2 = 'https://i.pinimg.com/originals/b6/9c/b2/b69cb232b50b1226a9245e19b0e4d455.jpg'\n",
        "!wget $url2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-11 18:33:22--  https://images.drive.ru/i/0/5ecf4bfeec05c49473000003.jpg\n",
            "Resolving images.drive.ru (images.drive.ru)... 146.255.192.80, 146.255.192.81\n",
            "Connecting to images.drive.ru (images.drive.ru)|146.255.192.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [image/jpeg]\n",
            "Saving to: ‘5ecf4bfeec05c49473000003.jpg’\n",
            "\n",
            "5ecf4bfeec05c494730     [  <=>               ] 117.72K   215KB/s    in 0.5s    \n",
            "\n",
            "2021-06-11 18:33:24 (215 KB/s) - ‘5ecf4bfeec05c49473000003.jpg’ saved [120548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9n9kOMuUbOW",
        "outputId": "74ac9e6e-22d0-47b8-a96f-0012b796f980"
      },
      "source": [
        "!python detect.py --source /content/yolov5/b69cb232b50b1226a9245e19b0e4d455.jpg --weights $trained_weights --img 256 --max-det 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, half=False, hide_conf=False, hide_labels=False, imgsz=256, iou_thres=0.45, line_thickness=3, max_det=1, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=False, source='/content/yolov5/b69cb232b50b1226a9245e19b0e4d455.jpg', update=False, view_img=False, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'])\n",
            "YOLOv5 🚀 v5.0-180-ge8c5237 torch 1.8.1+cu101 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 392 layers, 47650641 parameters, 0 gradients\n",
            "image 1/1 /content/yolov5/b69cb232b50b1226a9245e19b0e4d455.jpg: 192x256 1 Eagle Talon Hatchback 1998, Done. (0.021s)\n",
            "Results saved to runs/detect/exp6\n",
            "Done. (0.070s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-33g1Qr5s4YZ",
        "outputId": "65abf1d4-0903-4417-f6ee-43005edd00ce"
      },
      "source": [
        "!python detect.py --source /content/val/images --weights /content/yolov5/runs/train/exp3/weights/best.pt --img 256 --max-det 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, half=False, hide_conf=False, hide_labels=False, imgsz=256, iou_thres=0.45, line_thickness=3, max_det=1, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=False, source='/content/val/images', update=False, view_img=False, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'])\n",
            "YOLOv5 🚀 v5.0-181-g4984cf5 torch 1.8.1+cu101 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"detect.py\", line 204, in <module>\n",
            "    detect(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"detect.py\", line 56, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "  File \"/content/yolov5/models/experimental.py\", line 119, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 579, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train/exp3/weights/best.pt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJRjm50vySH5",
        "outputId": "d5fcffaf-76d5-43c1-9c24-7447dd991da2"
      },
      "source": [
        "url3 = \"https://www.bmw.ru/content/dam/bmw/common/all-models/3-series/sedan/2018/navigation/bmw-3-series-modellfinder.png/_jcr_content/renditions/cq5dam.resized.img.585.low.time1579021049723.png\"\n",
        "!wget $url3\n",
        "\n",
        "!python detect.py --source /content/yolov5/cq5dam.resized.img.585.low.time1579021049723.png --weights /content/yolov5/runs/train/exp3/weights/best.pt --img 256 --max-det 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, half=False, hide_conf=False, hide_labels=False, imgsz=256, iou_thres=0.45, line_thickness=3, max_det=1, name='exp', nosave=False, project='runs/detect', save_conf=False, save_crop=False, save_txt=False, source='/content/yolov5/cq5dam.resized.img.585.low.time1579021049723.png', update=False, view_img=False, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'])\n",
            "YOLOv5 🚀 v5.0-181-g4984cf5 torch 1.8.1+cu101 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"detect.py\", line 204, in <module>\n",
            "    detect(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"detect.py\", line 56, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "  File \"/content/yolov5/models/experimental.py\", line 119, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 579, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train/exp3/weights/best.pt'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}